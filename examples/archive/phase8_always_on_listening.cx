// ğŸ¤ Phase 8.2: Always-On Listening Agent - Live Voice Interaction
// Building on successful Phase 8 real-time architecture

class AuraListeningAgent
{
    uses textGen from Cx.AI.TextGeneration;
    uses tts from Cx.AI.TextToSpeech;
    
    name: string;
    isListening: boolean;
    isAwake: boolean;
    conversationActive: boolean;
    
    constructor(config)
    {
        this.name = config.name;
        this.isListening = true;  // Always listening for wake words
        this.isAwake = false;
        this.conversationActive = false;
        
        print("ğŸ¤ " + this.name + " initialized - Always listening for 'Aura on'");
        
        // Start continuous listening
        emit audio.listen.start, {
            agentName: this.name,
            mode: "continuous"
        };
    }
    
    function wakeUp()
    {
        this.isAwake = true;
        this.conversationActive = true;
        
        var greeting = textGen.GenerateAsync("Generate a brief, enthusiastic wake-up greeting", {
            temperature: 0.8,
            maxTokens: 30
        });
        
        tts.SpeakAsync("BEEP-BOOP! Aura is awake! " + greeting);
        
        emit aura.awakened, {
            agentName: this.name,
            timestamp: "now"
        };
        
        print("ğŸ”¥ " + this.name + " is now AWAKE and ready for conversation!");
    }
    
    function sleep()
    {
        this.isAwake = false;
        this.conversationActive = false;
        
        tts.SpeakAsync("beep-boop... Aura going to sleep... zzz...");
        
        emit aura.sleeping, {
            agentName: this.name,
            timestamp: "now"
        };
        
        print("ğŸ˜´ " + this.name + " is now sleeping - listening only for wake commands");
    }
    
    function processVoiceInput(transcript, confidence)
    {
        if (transcript == "aura on")
        {
            this.wakeUp();
            return;
        }
        
        if (transcript == "AURA ON")
        {
            this.wakeUp();
            return;
        }
        
        if (transcript == "aura off")
        {
            this.sleep();
            return;
        }
        
        if (transcript == "AURA OFF")
        {
            this.sleep();
            return;
        }
        
        // Only process other commands if awake
        if (!this.isAwake)
        {
            return;
        }
        
        // Generate AI response for conversation
        var prompt = "Respond as a helpful AI assistant with brief, friendly responses. User said: '" + transcript + "'";
        var response = textGen.GenerateAsync(prompt, {
            temperature: 0.7,
            maxTokens: 100
        });
        
        // Speak the response
        tts.SpeakAsync(response);
        
        emit conversation.processed, {
            agentName: this.name,
            userInput: transcript,
            aiResponse: response,
            confidence: confidence
        };
        
        print("ğŸ—£ï¸  User: " + transcript);
        print("ğŸ¤– " + this.name + ": " + response);
    }
    
    // Always-on audio processing - Priority #1 from Aura framework
    on live.audio (payload)
    {
        if (payload.transcript)
        {
            if (payload.confidence > 0.7)
            {
                this.processVoiceInput(payload.transcript, payload.confidence);
            }
        }
    }
    
    // Wake command event handler
    on aura.wake.command (payload)
    {
        if (payload.agentName == this.name)
        {
            this.wakeUp();
        }
    }
    
    // Sleep command event handler
    on aura.sleep.command (payload)
    {
        if (payload.agentName == this.name)
        {
            this.sleep();
        }
    }
    
    // Voice command processing
    on voice.command.received (payload)
    {
        if (this.isAwake)
        {
            this.processVoiceInput(payload.command, payload.confidence);
        }
    }
}

class ConversationMonitorAgent
{
    name: string;
    conversationLog: object;
    
    constructor(config)
    {
        this.name = config.name;
        this.conversationLog = [];
        
        print("ğŸ“Š " + this.name + " monitoring conversation flow");
    }
    
    on aura.awakened (payload)
    {
        print("ğŸŒ… AURA AWAKENED: " + payload.agentName + " is now active");
        
        emit system.status.update, {
            status: "active",
            agentName: payload.agentName,
            timestamp: payload.timestamp
        };
    }
    
    on aura.sleeping (payload)
    {
        print("ğŸŒ™ AURA SLEEPING: " + payload.agentName + " in sleep mode");
        
        emit system.status.update, {
            status: "sleeping",
            agentName: payload.agentName,
            timestamp: payload.timestamp
        };
    }
    
    on conversation.processed (payload)
    {
        print("ğŸ’¬ CONVERSATION: User->'" + payload.userInput + "' AI->'" + payload.aiResponse + "'");
        
        // Add to conversation log
        var logEntry = {
            timestamp: "now",
            user: payload.userInput,
            ai: payload.aiResponse,
            confidence: payload.confidence
        };
        
        // In real implementation, would append to array
        print("ğŸ“ Logged conversation entry");
        
        emit conversation.logged, {
            entry: logEntry,
            agentName: payload.agentName
        };
    }
    
    on system.status.update (payload)
    {
        print("ğŸ”„ SYSTEM STATUS: " + payload.agentName + " -> " + payload.status);
    }
}

print("ğŸ¤ Phase 8.2: Always-On Conversational Intelligence");
print("=================================================");
print("ğŸ¯ Building on Phase 8 successful real-time architecture");
print("âœ… Adding always-on listening with wake word detection");
print("âœ… Implementing conversational AI with voice response");
print("");

try
{
    // Create always-on listening agents
    var listeningAgent = agent AuraListeningAgent({ name: "AuraBot" });
    var monitorAgent = agent ConversationMonitorAgent({ name: "ConversationMonitor" });
    
    print("ğŸ¤– Always-on agents created successfully");
    print("");
    
    // Simulate always-on listening scenarios
    print("ğŸ™ï¸  Simulating Always-On Listening:");
    print("===================================");
    
    // Simulate continuous audio input
    emit live.audio, {
        transcript: "hello there",
        confidence: 0.9
    };
    
    emit live.audio, {
        transcript: "aura on",
        confidence: 0.95
    };
    
    emit live.audio, {
        transcript: "what is the weather today",
        confidence: 0.85
    };
    
    emit live.audio, {
        transcript: "tell me a joke",
        confidence: 0.88
    };
    
    emit live.audio, {
        transcript: "aura off",
        confidence: 0.92
    };
    
    emit live.audio, {
        transcript: "this should be ignored",
        confidence: 0.8
    };
    
    print("");
    print("âœ… Phase 8.2 Always-On Demo Complete!");
    print("âœ… Wake word detection working");
    print("âœ… Conversational AI processing active");
    print("âœ… Voice interaction simulation successful");
    print("ğŸ¯ Ready for real microphone integration!");
    
}
catch (error)
{
    print("âŒ Error: " + error);
}
