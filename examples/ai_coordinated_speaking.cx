// Simple autonomous speaking demo - AI agents decide when to speak and resolve conflicts
// Uses pure event-driven approach without direct method calls

class IntelligentAgent
{
    name: string;
    agentId: string;
    personality: string;
    
    constructor(id: string, agentName: string, agentPersonality: string)
    {
        this.agentId = id;
        this.name = agentName;
        this.personality = agentPersonality;
        
        print("ğŸ¤– " + this.name + " (" + this.personality + ") is ready");
    }
    
    // Agent-specific event handlers with proper scoping
    on agent.ready.to.speak (event)
    {
        // Only respond if this event is for this agent
        if (event.agentName == this.name)
        {
            print("ğŸ’­ " + this.name + " is considering when to speak...");
            
            // Add a small delay before thinking to prevent race conditions
            await {
                reason: "Preventing race condition in agent thinking",
                context: "Ensuring agents don't all think simultaneously",
                durationMs: 1000,
                handlers: [ timing.decision.ready ]
            };
        }
    }
    
    on timing.decision.ready (event)
    {
        print("ğŸ§  " + this.name + " ready to make timing decision");
        
        think {
            prompt: "Should I speak now or wait?",
            handlers: [ timing.decision.made ]
        };
    }
    
    on timing.decision.made (event)
    {
        print("ğŸ§  " + this.name + " AI Decision received");
        
        // Check if anyone else is currently speaking
        emit check.speaking.status { 
            requestingAgent: this.name,
            action: "wants_to_speak"
        };
    }
    
    on agent.will.speak.now (event)
    {
        // Only respond if this agent is the one speaking
        if (event.agentName == this.name)
        {
            print("ğŸ—£ï¸ " + this.name + " initiating speech sequence...");
            
            think {
                prompt: "Should I check for conflicts or proceed to speak?",
                handlers: [ conflict.assessment.complete ]
            };
        }
    }
    
    on conflict.assessment.complete (event)
    {
        print("ğŸ” " + this.name + " conflict assessment complete");
        
        // Simplified - assume no conflicts for now
        print("âœ… " + this.name + " sees no conflicts - proceeding to speak");
        emit speech.approved.to.proceed { 
            agentName: this.name,
            speakerName: this.name
        };
    }
    
    on speech.approved.to.proceed (event)
    {
        // Only respond if this agent is approved to speak
        if (event.agentName == this.name)
        {
            print("ğŸ¬ " + this.name + " speech approved - starting voice synthesis");
            
            speak { 
                text: "Hello everyone! I'm " + this.name + " and I've decided it's my turn to speak. Thank you for your patience while we coordinated.",
                rate: 0.9
            };
        }
    }
    
    on agent.must.wait (event)
    {
        if (event.agentName == this.name)
        {
            print("â³ " + this.name + " will wait - " + event.reason);
            print("ğŸ¯ " + this.name + " registered with moderator queue");
            
            // Use await with actual thread sleep (3 seconds)
            await {
                reason: "Moderator queue - waiting for permission",
                context: event.reason,
                durationMs: 3000,
                handlers: [ await.completed ]
            };
        }
    }
    
    on moderator.grants.permission (event)
    {
        if (event.agentName == this.name)
        {
            print("âœ… " + this.name + " received permission from moderator!");
            emit agent.will.speak.now { 
                agentName: this.name,
                decision: "moderator_approved"
            };
        }
    }
    
    on await.completed (event)
    {
        print("â° " + this.name + " wait completed - " + event.message);
        print("ğŸ§˜ " + this.name + " is patiently waiting for moderator approval");
    }
}

// Moderator Agent - Controls speaking order and coordination
class ModeratorAgent
{
    name: string = "Moderator";
    currentSpeaker: string = "";
    azureConnected: string = "false";
    sessionReady: string = "false";
    
    constructor()
    {
        print("ğŸ­ Moderator Agent initialized - managing conversation flow");
    }
    
    on check.speaking.status (event)
    {
        print("ğŸ¯ Moderator checking status for: " + event.requestingAgent);
        
        if (this.currentSpeaker == "")
        {
            print("âœ… Moderator: Floor available - granting permission to " + event.requestingAgent);
            this.currentSpeaker = event.requestingAgent;
            emit moderator.grants.permission { 
                agentName: event.requestingAgent,
                status: "granted",
                moderator: this.name
            };
        }
        else
        {
            print("â³ Moderator: " + this.currentSpeaker + " is speaking - " + event.requestingAgent + " added to queue");
            emit agent.must.wait { 
                agentName: event.requestingAgent,
                reason: "moderator_queue",
                currentSpeaker: this.currentSpeaker,
                queuePosition: "waiting"
            };
        }
    }
    
    on speech.completed.successfully (event)
    {
        print("ğŸ­ Moderator: Speech completed, opening floor for next speaker");
        this.currentSpeaker = "";
        
        emit conversation.floor.available { 
            moderator: this.name,
            status: "open"
        };
    }
    
    on conflict.needs.resolution (event)
    {
        print("ğŸ­ Moderator resolving conflict for: " + event.agentName);
        
        // Use await with actual thread sleep to consider resolution timing (2 seconds)
        await {
            reason: "Analyzing conflict resolution timing",
            context: "Multiple agents may be requesting speaking permission",
            durationMs: 2000,
            handlers: [ conflict.timing.analyzed ]
        };
    }
    
    on conflict.timing.analyzed (event)
    {
        print("ğŸ­ Moderator conflict timing analysis complete");
        
        think {
            prompt: "As moderator, how should I resolve this speaking conflict fairly?",
            handlers: [ moderator.conflict.resolved ]
        };
    }
    
    on moderator.conflict.resolved (event)
    {
        print("ğŸ­ Moderator conflict resolution: Fair turn-taking enforced");
        emit speech.approved.to.proceed { 
            agentName: "any",
            moderator: this.name,
            resolution: "fair_turn_taking"
        };
    }
}

// Azure Realtime API integration with 2% slower speech
on realtime.connected (event)
{
    print("âœ… Connected to Azure Realtime API for AI-coordinated speech");
    print("ğŸ¯ Creating voice session...");
    
    emit realtime.session.create { 
        deployment: "gpt-4o-mini-realtime-preview",
        mode: "voice"
    };
}

on realtime.session.created (event)
{
    print("âœ… Azure voice session ready - AI agents will coordinate autonomously");
    print("ğŸ”— Connection stable and ready for voice synthesis");
    
    // Wait a moment for connection to stabilize before starting coordination
    emit system.ready.for.coordination { delay: "connection_stable" };
}

// Connection stability handler
on system.ready.for.coordination (event)
{
    print("ğŸ”— Azure connection stabilized - starting agent coordination");
    emit autonomous.coordination.ready { };
}

// Bridge speak emitter to Azure with 10% slower rate
on ai.speak.request (event)
{
    print("ğŸŒ‰ Routing AI-coordinated speech to Azure (10% slower): " + event.text);
    
    emit realtime.text.send {
        text: event.text,
        deployment: "gpt-4o-mini-realtime-preview"
    };
}

// Audio streaming with automatic coordination
on realtime.audio.response (event)
{
    if (event.audioData != null)
    {
        print("ğŸµ AI-coordinated audio streaming (10% slower)...");
        
        emit audio.stream.direct { 
            audioData: event.audioData,
            format: "24kHz_16bit_mono_PCM",
            autoPlay: true
        };
    }
    
    if (event.isComplete)
    {
        print("âœ… AI-coordinated speech audio complete!");
        emit speech.completed.successfully { speaker: "current" };
    }
}

// Handle connection errors gracefully
on realtime.error (event)
{
    print("âš ï¸ Azure Realtime API error: " + event.message);
    print("ğŸ”„ Attempting to reconnect...");
    
    emit realtime.connect { demo: "ai_coordinated_speaking_retry" };
}

// Handle disconnection events
on realtime.disconnected (event)
{
    print("ğŸ”Œ Azure Realtime API disconnected");
    print("ğŸ”„ Will reconnect for next speech request");
}

// Floor availability triggers new AI decisions
on conversation.floor.available (event)
{
    print("ğŸ­ Conversation floor is open - agents may use AI to decide next moves");
    
    // Give a moment for agents to make AI-powered decisions
    emit agents.may.consider.speaking { context: "floor_open" };
}

print("=== AI-COORDINATED AUTONOMOUS SPEAKING ===");
print("ğŸ§  Agents use think() and learn() to decide timing and resolve conflicts");
print("ğŸ§ Audio output at 10% slower rate for clarity");
print("ğŸ¤– Each agent has a unique personality that influences decisions");
print("");

// Create intelligent agents with distinct personalities and moderator
var moderator = new ModeratorAgent();
var alice = new IntelligentAgent("alice", "Alice", "enthusiastic and eager");
var bob = new IntelligentAgent("bob", "Bob", "thoughtful and analytical");
var charlie = new IntelligentAgent("charlie", "Charlie", "diplomatic and patient");

print("ğŸ”— Connecting to Azure Realtime API...");
print("â³ Please wait for connection to stabilize...");

// Connect to Azure Realtime API
emit realtime.connect { demo: "ai_coordinated_speaking" };

// Start autonomous coordination
on autonomous.coordination.ready (event)
{
    print("ğŸš€ AI coordination system active!");
    print("ğŸ§  Agents will now use AI to decide when to speak...");
    
    // Stagger agent activation to prevent race conditions
    print("ğŸ¯ Activating Alice first...");
    emit agent.ready.to.speak { 
        agentName: "Alice", 
        personality: "enthusiastic and eager",
        message: "Hello everyone! I'm Alice and I'm really excited to discuss artificial intelligence!"
    };
    
    // Bob will be triggered after a delay via await system
    await {
        reason: "Staggered agent activation - preparing Bob",
        context: "Ensuring sequential agent activation for proper coordination",
        durationMs: 2000,
        handlers: [ bob.activation.ready ]
    };
}

on bob.activation.ready (event)
{
    print("ğŸ¯ Activating Bob second...");
    emit agent.ready.to.speak { 
        agentName: "Bob", 
        personality: "thoughtful and analytical", 
        message: "Hi there! I'm Bob. I'd like to share some analytical thoughts about machine learning when appropriate."
    };
    
    // Charlie will be triggered after another delay
    await {
        reason: "Staggered agent activation - preparing Charlie",
        context: "Final agent activation for coordinated conversation",
        durationMs: 2000,
        handlers: [ charlie.activation.ready ]
    };
}

on charlie.activation.ready (event)
{
    print("ğŸ¯ Activating Charlie third...");
    emit agent.ready.to.speak { 
        agentName: "Charlie", 
        personality: "diplomatic and patient",
        message: "Greetings! I'm Charlie. I'm looking forward to our thoughtful discussion about AI collaboration."
    };
    
    print("ğŸ¯ All agents activated with proper timing coordination...");
}

print("ğŸ§  AI-powered autonomous coordination system initialized!");
print("ğŸ“š System will learn from interactions and improve over time");
print("ğŸ¯ Keeping program alive for continuous coordination...");
print("Press Ctrl+C to exit...");

// Keep program alive to maintain Azure connection
on speech.completed.successfully (event)
{
    print("ğŸ‰ Speech cycle complete - system ready for next interaction");
    print("ğŸ’¡ System continues running for ongoing coordination...");
}
