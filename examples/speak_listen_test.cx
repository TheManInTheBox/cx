// Test speak and listen functionality with Azure Realtime API
print("ðŸŽ¤ Testing Speak and Listen Integration with Azure Realtime API");

class VoiceTest
{
    name: string = "VoiceTest";
    
    function startVoiceSession()
    {
        print("ðŸŽ§ Starting voice session...");
        
        // Connect to Azure Realtime API first
        emit realtime.connect { demo: "voice_test" };
    }
    
    function sendVoiceMessage(text: string)
    {
        print("ðŸ”Š Sending voice message: " + text);
        
        // Send text to Azure Realtime API for voice synthesis
        emit realtime.text.send { 
            text: text,
            deployment: "gpt-4o-mini-realtime-preview"
        };
    }
    
    on realtime.connected (event)
    {
        print("âœ… Azure Realtime connected - creating session");
        emit realtime.session.create { 
            deployment: "gpt-4o-mini-realtime-preview",
            test: "voice"
        };
    }
    
    on realtime.session.created (event)
    {
        print("âœ… Voice session created - ready for voice input/output");
        this.sendVoiceMessage("Hello, this is a test of the voice system.");
    }
    
    on realtime.text.response (event)
    {
        print("âœ… Voice response received: " + event.content);
        print("  Complete: " + event.isComplete);
        
        if (event.isComplete)
        {
            print("ðŸŽ‰ Voice test successful!");
        }
    }
    
    on realtime.audio.response (event)
    {
        print("ðŸ”Š Audio response received - " + event.length + " bytes");
    }
}

var voiceTest = new VoiceTest();
voiceTest.startVoiceSession();

print("ðŸŽ‰ Voice system test initiated!");
