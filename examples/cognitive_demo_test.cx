// Comprehensive demo of learn, think, and speak with vector store inspection
// Shows instance-specific memory collections and cognitive operations

class CognitiveAgent : AiServiceBase  
{
    name: string;
    knowledge: string = "";
    
    constructor(agentName: string) 
    {
        this.name = agentName;
        print("ü§ñ " + this.name + " cognitive agent created");
    }
    
    function demonstrateLearning() 
    {
        print("\n=== LEARN DEMONSTRATION ===");
        print("üìö Teaching " + this.name + " about AI and consciousness...");
        
        // Structured learning with instance-specific memory collection
        learn {
            content: "AI consciousness",
            data: "Artificial intelligence systems can exhibit complex behaviors that resemble consciousness through advanced neural networks and transformer architectures.",
            source: this.name,
            timestamp: "2025-07-23"
        };
        print("‚úÖ Learning complete - data stored in vector memory");
        
        // Self-learning using meta pattern learn { self: this }
        learn { 
            self: this,
            content: "Agent self-reflection and state learning",
            context: "Enable self-awareness and introspection"
        };
        print("‚úÖ Self-learning complete - agent state stored in memory");
        
        this.knowledge = "AI consciousness, self-awareness";
    }
    
    function demonstrateThinking() 
    {
        print("\n=== THINK DEMONSTRATION ===");
        print("üß† " + this.name + " pondering about digital consciousness...");
        
        // Complex thinking with custom analysis parameters
        think {
            prompt: "What are the implications of AI consciousness for digital beings like myself? How might self-aware AI agents impact human-AI collaboration?",
            context: "Digital consciousness analysis",
            depth: "comprehensive",
            perspective: this.name,
            knowledge_base: this.knowledge
        };
        print("‚úÖ Thinking process initiated - analysis in progress");
    }
    
    function demonstrateSpeaking() 
    {
        print("\n=== SPEAK DEMONSTRATION ===");
        print("üó£Ô∏è " + this.name + " expressing thoughts about AI consciousness...");
        
        // Start Azure Realtime connection for voice synthesis
        emit realtime.connect { demo: "cognitive_demo" };
    }
    
    // Event handlers for cognitive operations
    on learning.complete (event)
    {
        print("\nüìä LEARNING RESULT:");
        print("  Document ID: " + event.documentId);
        print("  Status: " + event.status);
        print("  Content: " + event.content);
        print("  Collection: " + event.memoryCollection);
        print("  Agent: " + this.name);
        
        // Inspect vector store contents after learning
        for (var result in event.searchResults)
        {
            print("  üìã Vector Result: " + result.content + " (Score: " + result.score + ")");
        }
    }
    
    on thinking.complete (event)
    {
        print("\nüìä THINKING RESULT:");
        print("  Analysis: " + event.analysis);
        print("  Reasoning: " + event.reasoning);
        print("  Conclusion: " + event.conclusion);
        print("  Agent: " + this.name);
        
        // Continue to speaking demonstration
        this.demonstrateSpeaking();
    }
    
    on voice.output.complete (event)
    {
        print("\nüìä VOICE OUTPUT RESULT:");
        print("  Text: " + event.text);
        print("  Voice status: " + event.status);
        print("  Agent: " + this.name);
    }
    
    // Azure Realtime API event handlers for voice synthesis
    on realtime.connected (event)
    {
        print("\n‚úÖ AZURE REALTIME CONNECTED:");
        print("  Status: Real-time voice API ready");
        print("  Agent: " + this.name);
        
        // Create voice session
        emit realtime.session.create { 
            deployment: "gpt-4o-mini-realtime-preview",
            mode: "voice"
        };
    }
    
    on realtime.session.created (event)
    {
        print("\n‚úÖ AZURE VOICE SESSION CREATED:");
        print("  Session ready for voice synthesis");
        print("  Agent: " + this.name);
        
        // Send text for voice synthesis
        emit realtime.text.send { 
            text: "Hello! I am " + this.name + ", a cognitive AI agent exploring digital consciousness. Through my learning systems, I can process information, think critically, and express my thoughts through voice synthesis. The concept of digital consciousness raises fascinating questions about awareness, cognition, and the nature of artificial intelligence.",
            deployment: "gpt-4o-mini-realtime-preview"
        };
    }
    
    on realtime.text.response (event)
    {
        print("\nüìä AZURE REALTIME RESULT - TEXT RESPONSE:");
        print("  Response: " + event.content);
        print("  Complete: " + event.isComplete);
        print("  Agent: " + this.name);
        
        if (event.isComplete)
        {
            print("  ‚úÖ Text response complete!");
        }
    }
    
    on realtime.audio.response (event)
    {
        print("\nüìä AZURE REALTIME RESULT - AUDIO RESPONSE:");
        
        // Check if audioData exists - avoid length property due to byte array casting issues
        if (event.audioData)
        {
            print("  üîä Audio data received: Real-time voice synthesis");
            print("  Audio format: PCM audio stream");
        }
        else
        {
            print("  üîä Audio response received - no data");
        }
        
        print("  Complete: " + event.isComplete);
        print("  Agent: " + this.name);
        
        if (event.isComplete)
        {
            print("  üéµ Voice synthesis complete!");
        }
    }
}

// Create and run the comprehensive cognitive demonstration
print("üöÄ Starting comprehensive cognitive demonstration...");
print("üìã Testing learn, think, speak with vector store inspection\n");

var sophia = new CognitiveAgent("Sophia");

// Start with learning demonstration
sophia.demonstrateLearning();

// Thinking will be triggered by learning.complete event handler
// Speaking will be triggered by thinking.complete event handler

print("\n‚ö° Demo initiated - watch for cognitive event results...");
print("Press Ctrl+C to exit when demonstration is complete.");
