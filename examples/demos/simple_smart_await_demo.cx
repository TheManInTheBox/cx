// SMART AWAIT DEMO - Simple and Working
// Demonstrates smart await coordination with slowed speech and real-time audio
// Features: AI-determined optimal timing, turn-based coordination, 10% slower speech

print("ğŸ­ Smart Await Demo");
print("AI-Optimized Timing Coordination");
print("================================");

class SmartAgent
{
    name: string;
    speechSpeed: number = 0.9; // 10% slower speech
    
    constructor(agentName: string)
    {
        this.name = agentName;
        print("ğŸ¯ " + this.name + " created with smart await capabilities");
        print("  Speech speed: " + this.speechSpeed + " (10% slower)");
    }
    
    function startDemo()
    {
        print("ğŸš€ " + this.name + " starting smart await demonstration...");
        
        // âœ… SMART AWAIT: AI-determined optimal preparation timing
        await { 
            reason: "demo_preparation_" + this.name,
            context: "Agent " + this.name + " preparing for smart await demonstration",
            minDurationMs: 1000,
            maxDurationMs: 3000,
            handlers: [ preparation.complete ]
        };
    }
    
    function speakWithOptimalTiming()
    {
        print("ğŸ¤ " + this.name + " preparing speech with optimal timing...");
        
        // âœ… SMART AWAIT: Pre-speech timing optimization
        await { 
            reason: "speech_timing_" + this.name,
            context: "Optimizing speech synthesis timing for " + this.name + " with slowed speed",
            minDurationMs: 500,
            maxDurationMs: 2000,
            handlers: [ speech.timing.ready ]
        };
    }
    
    function synthesizeVoice()
    {
        print("ğŸ”Š " + this.name + " connecting to Azure Realtime API...");
        
        // Connect to Azure for voice synthesis
        emit realtime.connect { 
            demo: "smart_await_" + this.name.toLowerCase(),
            agent: this.name,
            speechSpeed: this.speechSpeed
        };
    }
    
    function completeDemo()
    {
        print("âœ… " + this.name + " completing demonstration...");
        
        // âœ… SMART AWAIT: Completion timing
        await { 
            reason: "demo_completion_" + this.name,
            context: "Final smart await optimization for " + this.name + " demo completion",
            minDurationMs: 1000,
            maxDurationMs: 2500,
            handlers: [ demo.complete ]
        };
    }
    
    // âœ… PREPARATION COMPLETE: Move to speech phase
    on preparation.complete (event)
    {
        if (event.reason.indexOf(this.name) >= 0)
        {
            print("ğŸ§  " + this.name + " preparation optimized (" + event.actualDurationMs + "ms)");
            print("  Smart await determined optimal timing");
            this.speakWithOptimalTiming();
        }
    }
    
    // âœ… SPEECH TIMING READY: Start voice synthesis
    on speech.timing.ready (event)
    {
        if (event.reason.indexOf(this.name) >= 0)
        {
            print("ğŸ™ï¸ " + this.name + " speech timing optimized (" + event.actualDurationMs + "ms)");
            this.synthesizeVoice();
        }
    }
    
    // âœ… AZURE REALTIME: Connection handler
    on realtime.connected (event)
    {
        print("ğŸ”— " + this.name + " connected to Azure Realtime API");
        
        emit realtime.session.create { 
            deployment: "gpt-4o-mini-realtime-preview",
            mode: "voice",
            voice: "alloy",
            agent: this.name,
            speechSpeed: this.speechSpeed
        };
    }
    
    // âœ… SESSION CREATED: Start speaking
    on realtime.session.created (event)
    {
        print("ğŸ™ï¸ " + this.name + " voice session ready - speaking with smart await coordination");
        
        var message = "Hello! I am " + this.name + " demonstrating smart await with optimized timing. My speech is 10% slower for better clarity.";
        
        emit realtime.text.send { 
            text: message,
            deployment: "gpt-4o-mini-realtime-preview",
            voice: "alloy",
            speed: this.speechSpeed,
            agent: this.name
        };
    }
    
    // âœ… AUDIO RESPONSE: Handle speech with slowed speed
    on realtime.audio.response (event)
    {
        print("ğŸ”Š " + this.name + " audio response (speed: " + this.speechSpeed + ")");
        
        if (event.audioData != null)
        {
            print("  Audio size: " + event.audioSize + " bytes");
            print("  Audio format: " + event.audioFormat);
            print("  Sample rate: " + event.sampleRate + "Hz");
            
            // Direct audio streaming with NAudio playback
            emit audio.stream.direct { 
                audioData: event.audioData,
                format: event.audioFormat,
                sampleRate: event.sampleRate,
                autoPlay: true,
                source: "smart_await_" + this.name,
                speechSpeed: this.speechSpeed,
                agent: this.name
            };
        }
        
        if (event.isComplete)
        {
            print("âœ… " + this.name + " speech synthesis complete with smart await optimization");
            this.completeDemo();
        }
    }
    
    // âœ… DEMO COMPLETE: Final smart await demonstration
    on demo.complete (event)
    {
        if (event.reason.indexOf(this.name) >= 0)
        {
            print("ğŸ‰ " + this.name + " smart await demo complete (" + event.actualDurationMs + "ms final timing)");
            
            emit agent.demo.finished { 
                agent: this.name,
                speechSpeed: this.speechSpeed,
                totalOptimizations: 3,
                success: true
            };
        }
    }
}

// âœ… GLOBAL SMART AWAIT HANDLERS
on await.smart.complete (event)
{
    print("ğŸ§  Global smart await optimization:");
    print("  Reason: " + event.reason);
    print("  Duration: " + event.actualDurationMs + "ms");
    print("  Context: " + event.context);
    print("  âœ… AI determined this was optimal timing");
}

on await.completed (event)
{
    print("â° Await operation completed:");
    print("  Duration: " + event.actualDurationMs + "ms");
    print("  Success: " + event.success);
    print("  Message: " + event.message);
}

// âœ… AUDIO STREAMING HANDLERS
on audio.stream.direct (event)
{
    print("ğŸ”Š Smart await audio streaming:");
    print("  Agent: " + event.agent);
    print("  Speed: " + event.speechSpeed + " (10% slower)");
    print("  Source: " + event.source);
    print("  Format: " + event.format);
    if (event.audioData != null)
    {
        print("  ğŸµ Playing audio through NAudio...");
    }
}

// âœ… DEMO COMPLETION HANDLER
on agent.demo.finished (event)
{
    print("");
    print("ğŸ† SMART AWAIT DEMO RESULTS:");
    print("  Agent: " + event.agent);
    print("  Speech Speed: " + event.speechSpeed + " (10% slower)");
    print("  Total Optimizations: " + event.totalOptimizations);
    print("  Success: " + event.success);
    print("âœ… Smart await demonstration completed successfully!");
    print("");
    print("ğŸ¯ SMART AWAIT FEATURES DEMONSTRATED:");
    print("  âœ… AI-determined optimal timing");
    print("  âœ… Real-time audio synthesis with slowed speech");
    print("  âœ… Coordinated event-driven flow");
    print("  âœ… Azure OpenAI Realtime API integration");
    print("  âœ… Multiple timing optimization points");
}

// ğŸš€ START THE SMART AWAIT DEMONSTRATION
print("ğŸ­ SMART AWAIT DEMONSTRATION:");
print("âœ… Speech speed: 90% (10% slower)");
print("âœ… AI-determined optimal timing coordination");
print("âœ… Real-time audio synthesis with Azure OpenAI");
print("âœ… Multiple optimization phases");
print("");

print("ğŸš€ Creating smart agent...");
var smartAgent = new SmartAgent("Alice");

print("ğŸ¯ Starting smart await demonstration...");
smartAgent.startDemo();

print("");
print("ğŸš€ Smart await system initialized!");
print("â° Watch for AI-optimized timing coordination...");
