// Voice output test with text-to-speech synthesis
on system.start (event)
{
    print("🔊 Testing Voice Output System");
    print("Connecting to Azure Realtime API for voice synthesis...");
    
    // Connect to Azure Realtime API for voice synthesis
    emit realtime.connect { demo: "voice_output_test" };
}

on realtime.connected (event)
{
    print("✅ Connected to Azure Realtime API");
    print("Creating voice session for speech synthesis...");
    
    emit realtime.session.create { 
        deployment: "gpt-4o-mini-realtime-preview",
        mode: "voice"
    };
}

on realtime.session.created (event)
{
    print("✅ Voice session created");
    print("Sending text for speech synthesis...");
    
    // Send text to be converted to speech
    emit realtime.text.send { 
        text: "Hello! This is a test of the voice output system. You should be able to hear this message through your speakers.",
        deployment: "gpt-4o-mini-realtime-preview"
    };
}

on realtime.audio.response (event)
{
    print("🔊 Audio response received from Azure");
    print("Audio data type: " + typeof(event.audioData));
    
    // Always emit the voice output event when we get audio data
    emit voice.output.play {
        audioData: event.audioData,
        sampleRate: 24000,
        channels: 1
    };
}

on voice.output.started (event)
{
    print("✅ Audio playback started successfully!");
    print("🔊 You should now hear the synthesized speech");
    print("Audio details:");
    print("  Length: " + event.audioLength + " bytes");
    print("  Sample Rate: " + event.sampleRate + "Hz");
    print("  Channels: " + event.channels);
}

on voice.output.completed (event)
{
    print("🎉 Audio playback completed!");
    print("Voice output system test successful");
}

on voice.output.error (event)
{
    print("❌ Voice output error occurred:");
    print("Error: " + event.error);
}

on realtime.text.response (event)
{
    print("Text response received: " + event.content);
    print("Is complete: " + event.isComplete);
}
