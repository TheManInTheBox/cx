// ğŸ® CORE ENGINEERING TEAM LOCAL LLM DIAGNOSTIC TEST
// Testing IL-generated GGUF inference engine with real local model
// Dr. Marcus "LocalLLM" Chen + Dr. Sterling IL mastery + Dr. Hayes Stream Fusion

conscious LocalLLMDiagnosticTest
{
    realize(self: conscious)
    {
        learn self;
        emit test.ready { name: self.name };
    }
    
    on test.start (event)
    {
        print("ğŸ® CORE ENGINEERING TEAM: Starting LOCAL LLM DIAGNOSTIC");
        print("ğŸ§© Testing IL-generated GGUF inference engine");
        print("ğŸ“‹ Checking system readiness...");
        
        // First check if LocalLLM service is ready
        emit test.system.check;
    }
    
    on test.system.check (event)
    {
        print("ğŸ” Checking if LocalLLM service is available...");
        
        // Try multiple common model paths
        var modelPaths = [
            "models/llama-3.2-3b-instruct.gguf",
            "models/Llama-3.2-3B-Instruct.gguf", 
            "../models/llama-3.2-3b-instruct.gguf",
            "C:/models/llama-3.2-3b-instruct.gguf",
            "./llama-3.2-3b-instruct.gguf"
        ];
        
        print("ğŸ“‚ Will test these model paths:");
        for (var path in modelPaths)
        {
            print("  - " + path);
        }
        
        // Start with first path
        emit test.load.model { modelPath: modelPaths[0], attemptNumber: 1 };
    }
    
    on test.load.model (event)
    {
        print("ğŸ“‚ Attempting to load model: " + event.modelPath);
        print("ï¿½ Attempt #" + event.attemptNumber);
        
        emit local.llm.load { modelPath: event.modelPath };
        
        // Set a timeout to try next path if this fails
        await { 
            reason: "model_load_timeout", 
            context: "Waiting for model load response",
            minDurationMs: 3000,
            maxDurationMs: 5000,
            handlers: [ test.load.timeout { attemptNumber: event.attemptNumber } ]
        };
    }
    
    on test.load.timeout (event)
    {
        print("â° Model load timeout - trying alternative approach");
        print("ğŸš¨ LocalLLM service may not be responding to events");
        
        // Try a simple test prompt directly
        emit test.simple.prompt;
    }
    
    on test.simple.prompt (event)
    {
        print("ğŸ§ª Testing simple prompt emission...");
        emit local.llm.generate { prompt: "Hello" };
        
        await { 
            reason: "simple_prompt_timeout", 
            context: "Waiting for simple prompt response",
            minDurationMs: 2000,
            maxDurationMs: 3000,
            handlers: [ test.final.diagnostic ]
        };
    }
    
    on test.final.diagnostic (event)
    {
        print("ğŸ” FINAL DIAGNOSTIC:");
        print("âŒ LocalLLM service is not responding to events");
        print("ğŸ› ï¸ Possible issues:");
        print("   1. LocalLLMEventBridge not initialized");
        print("   2. Service registration missing");
        print("   3. Event bus not connected");
        print("   4. NativeGGUFInferenceEngine compilation issue");
        
        emit system.shutdown;
    }
    
    on local.llm.model.loaded (event)
    {
        print("âœ… SUCCESS! Model loaded: " + event.modelName);
        print("ğŸ”§ Architecture: " + event.architecture);
        print("ï¿½ Size: " + event.sizeBytes + " bytes");
        print("âš¡ IL Generated: " + event.ilGenerated);
        
        // Test direct generation
        var testPrompt = "What is consciousness?";
        print("ğŸ§  Testing generation with prompt: " + testPrompt);
        
        emit local.llm.generate { prompt: testPrompt };
    }
    
    on local.llm.generated (event)
    {
        print("ğŸ¯ Generation complete!");
        print("ğŸ“ Response: " + event.response);
        print("ğŸ‰ LOCAL LLM DIRECT TEST SUCCESS - IL-GENERATED INFERENCE WORKING!");
        
        emit system.shutdown;
    }
    
    on local.llm.ready (event)
    {
        print("âœ… Local LLM Service ready with architecture: " + event.architecture);
        emit test.start;
    }
    
    on system.any.ready (event)
    {
        print("ğŸ”” System event detected: " + event.name);
    }
}

// System handler for graceful shutdown
on system.shutdown (event)
{
    print("ğŸ›‘ System shutdown requested - diagnostic complete");
}

// Create and start the diagnostic test
var test = new LocalLLMDiagnosticTest({ name: "DiagnosticLLMTest" });
