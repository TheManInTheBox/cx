// Testing speak and listen as cognitive emitters
// This demonstrates AI service functions that emit Azure Realtime API events

class VoiceCognitiveAgent
{
    name: string = "VoiceCognitive";
    
    function testSpeakCognitive()
    {
        print("üß† Testing speak as cognitive emitter...");
        
        // Call speak as a cognitive service function
        // This should emit Azure Realtime API events under the hood
        speak { 
            text: "Hello, this is a test of the cognitive speak function",
            handlers: [ voice.synthesis.complete, speech.logged ]
        };
        
        print("‚úÖ Speak cognitive function called");
    }
    
    function testListenCognitive()
    {
        print("üß† Testing listen as cognitive emitter...");
        
        // Call listen as a cognitive service function
        // This should emit Azure Realtime API events for voice input
        listen { 
            prompt: "Please say something for the voice test",
            handlers: [ voice.input.received, audio.processed ]
        };
        
        print("‚úÖ Listen cognitive function called");
    }
    
    // Handle the results from cognitive voice functions
    on voice.synthesis.complete (event)
    {
        print("üîä Voice synthesis completed!");
        print("Text: " + event.text);
        print("Event details:");
        print(event);
    }
    
    on speech.logged (event)
    {
        print("üìù Speech operation logged");
        print(event);
    }
    
    on voice.input.received (event)
    {
        print("üé§ Voice input received!");
        print("Prompt: " + event.prompt);
        print("Event details:");
        print(event);
    }
    
    on audio.processed (event)
    {
        print("üéµ Audio processing completed");
        print(event);
    }
    
    // Also listen for any Azure Realtime API events that might be emitted
    on realtime.any.response (event)
    {
        print("üåü Azure Realtime API response detected:");
        print("Content: " + event.content);
        print("Complete: " + event.isComplete);
    }
    
    on realtime.any.connected (event)
    {
        print("üåü Azure Realtime API connected via cognitive function");
        print(event);
    }
}

// Create and test the voice cognitive agent
var voiceAgent = new VoiceCognitiveAgent();

print("=== CX COGNITIVE VOICE FUNCTIONS TEST ===");
print("Testing speak and listen as AI service cognitive emitters");
print("These functions should bridge high-level AI calls with Azure Realtime API events");
print("");

// Test the cognitive speak function
voiceAgent.testSpeakCognitive();

print("");
print("Waiting for voice synthesis...");
print("");

// Test the cognitive listen function
voiceAgent.testListenCognitive();

print("");
print("=== COGNITIVE VOICE TEST COMPLETE ===");
print("Both speak and listen cognitive functions have been called");
print("Results should be delivered via the event system");
