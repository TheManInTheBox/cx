// Azure OpenAI Realtime API Demo - Phase 1 Connection Test
// Demonstrates WebSocket connection to Azure OpenAI Realtime API

class VoiceAgent 
{
    name: string;
    sessionId: string;
    
    constructor(agentName)
    {
        this.name = agentName;
        print("ğŸ¤ Created voice agent: " + this.name);
    }
    
    function testConnection()
    {
        print("ğŸ”Œ Testing Azure OpenAI Realtime API connection...");
        
        // Test basic connection to Azure OpenAI
        emit realtime.connect, { agent: this.name };
        
        print("âœ… Connection test initiated - check events for results");
    }
    
    function startVoiceSession()
    {
        print("ğŸš€ Starting voice session for " + this.name);
        
        // Create realtime session
        emit realtime.session.create, { 
            agent: this.name,
            config: "voice_enabled"
        };
    }
    
    function sendTestMessage()
    {
        print("ğŸ“ Sending test text message...");
        
        // Send text message via realtime API
        emit realtime.text.send, {
            text: "Hello from CX Language! This is a test of Azure OpenAI Realtime API integration.",
            agent: this.name
        };
    }
    
    // Event handlers for realtime responses
    on realtime.session.created (payload)
    {
        print("âœ… Voice session created successfully!");
        print("Session ID: " + payload.sessionId);
        this.sessionId = payload.sessionId;
        
        // Auto-send test message after session creation
        this.sendTestMessage();
    }
    
    on realtime.session.error (payload)
    {
        print("âŒ Voice session error: " + payload.error);
    }
    
    on realtime.message.received (payload)
    {
        print("ğŸ¯ Received AI response: " + payload.content);
        
        if (payload.isComplete)
        {
            print("âœ… Response complete from Azure OpenAI");
        }
    }
    
    on realtime.audio.received (payload)
    {
        print("ğŸ”Š Received audio response - " + payload.audioData.length + " bytes");
        
        if (payload.isComplete)
        {
            print("ğŸµ Audio response complete");
        }
    }
}

print("ğŸ¯ Azure OpenAI Realtime API Integration - Phase 1 Demo");
print("==================================================");
print("");
print("This demo tests the foundational WebSocket connection");
print("to Azure OpenAI Realtime API for voice processing.");
print("");

// Create voice-enabled agent
var voiceAgent = new VoiceAgent("AzureRealtimeTest");

// Test sequence
print("ğŸ”¬ Running connection tests...");
voiceAgent.testConnection();

print("");
print("â³ Starting voice session in 2 seconds...");

// Simulate delay then start session
// In production, this would be triggered by actual voice input
emit system.timer, { delay: 2000, action: "start_session" };

on system.timer (payload)
{
    if (payload.action == "start_session")
    {
        voiceAgent.startVoiceSession();
    }
}

print("");
print("ğŸ¤ Azure OpenAI Realtime API Phase 1 Integration Complete");
print("Next: Phase 2 - Real-time audio streaming implementation");
