// ğŸ¯ FINAL CLEAN CHAT AGENT - Direct Print Version
// Your local AI assistant for real conversation!

conscious FinalCleanAgent
{
    realize(self: conscious)
    {
        print("");
        print("ğŸ¯ FINAL CLEAN CHAT AGENT");
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        print("ğŸ‘‹ Hello! I'm your local AI assistant.");
        print("ğŸ’¡ Completely private - running locally!");
        print("âœ¨ Ready for clean conversation!");
        print("");
        
        learn self;
        emit chat.initialize;
    }
    
    on chat.initialize (event)
    {
        print("ğŸ”¥ Loading AI model...");
        
        emit local.llm.load { 
            modelPath: "models/local_llm/llama-3.2-3b-instruct-q4_k_m.gguf",
            purpose: "FinalCleanChat"
        };
    }
    
    on local.llm.model.loaded (event)
    {
        print("âœ… AI model ready!");
        print("");
        print("ğŸ® CONVERSATION STARTING");
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
        print("ğŸ’¬ Let me introduce myself...");
        print("");
        
        emit local.llm.generate {
            prompt: "Say hello in exactly 15 words. Introduce yourself as a helpful local AI assistant.",
            purpose: "Greeting"
        };
    }
    
    on local.llm.text.generated (event)
    {
        // Handle greeting
        is {
            context: "Is this the greeting response?",
            evaluate: "Check if purpose is Greeting",
            data: { purpose: event.purpose },
            handlers: [ show.greeting ]
        };
        
        // Handle main conversation
        is {
            context: "Is this the main conversation response?",
            evaluate: "Check if purpose is MainChat",
            data: { purpose: event.purpose },
            handlers: [ show.conversation ]
        };
    }
    
    on show.greeting (event)
    {
        print("ğŸ¤– AI: " + event.response);
        print("");
        print("Now let me solve a math problem:");
        print("ğŸ‘¤ Human: What is 23 + 23?");
        print("");
        
        emit local.llm.generate {
            prompt: "Calculate 23 + 23. Show your work and give the final answer.",
            purpose: "MainChat"
        };
    }
    
    on show.conversation (event)
    {
        print("ğŸ¤– AI: " + event.response);
        print("");
        print("ğŸ‰ CLEAN CONVERSATION SUCCESS!");
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        print("âœ… Local AI: WORKING");
        print("âœ… Real responses: WORKING");  
        print("âœ… Clean output: WORKING");
        print("âœ… No debug noise: SUCCESS");
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        print("");
        
        await {
            reason: "final_chat_complete",
            context: "Conversation complete pause",
            minDurationMs: 1000,
            maxDurationMs: 1000,
            handlers: [ chat.finished ]
        };
    }
    
    on chat.finished (event)
    {
        print("ğŸš€ Your clean local AI chat is ready!");
        print("âœ¨ Conversation complete!");
        
        emit system.shutdown;
    }
}

var finalAgent = new FinalCleanAgent({ name: "FinalCleanAgent" });

on system.start (event)
{
    print("ğŸ¯ STARTING FINAL CLEAN CHAT");
    emit chat.initialize;
}
